# Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies

Authors: Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai

TLDR: Which human behaviors can your large language model simulate? Turing Experiments are better than the Turing Test.

We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a
given language model, such as GPT-3, can simulate different aspects of human behavior. A TE
can also reveal consistent distortions in a language model’s simulation of a specific human behavior.
Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simu-
lating a representative sample of participants in human subject research. We give TEs that attempt
to replicate well-established findings in prior studies. We design a methodology for simulating TEs
and illustrate its use to compare how well different language models are able to reproduce classic eco-
nomic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sen-
tences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing find-
ings were replicated using recent models, while the last TE reveals a “hyper-accuracy distortion”
present in some language models, which could affect downstream applications in education and
the arts.

Keywords: Turing Test, Large Language Models, Evaluation Metrics

Pre-print: https://arxiv.org/abs/2208.10264

---

Code coming soon!
